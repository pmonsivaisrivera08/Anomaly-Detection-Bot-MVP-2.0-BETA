{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "33d7f54a",
        "outputId": "538bbf00-e10e-46b4-8d6d-7f79629b4863"
      },
      "source": [
        "# FINAL CODE - Versión Final Limpia y Completa\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from datetime import datetime, timezone\n",
        "import requests\n",
        "import pytz # Import pytz for timezone handling\n",
        "import matplotlib.pyplot as plt # Import matplotlib for plotting\n",
        "from google.colab import files # Import files for download\n",
        "import sys # Import sys to exit if needed\n",
        "import json # Import json for reading configuration files\n",
        "\n",
        "\n",
        "# --------- CONFIGURACION (Estas variables se establecen al inicio de la ejecucion) ----------\n",
        "# No es necesario modificar aqui directamente, se piden los valores al ejecutar o se cargan desde archivo.\n",
        "SYMBOLS = []\n",
        "PERIOD = \"\"\n",
        "INTERVAL = \"\"\n",
        "Z_THRESHOLD = 0.0\n",
        "IF_CONTAMINATION = 0.0\n",
        "# Added %K_smooth and %D to the default IF_FEATURES\n",
        "IF_FEATURES = [\"logret\", \"vol_20\", \"z_price\", \"vol_z\", \"price_vol_interaction\", \"rsi\", \"macd\", \"upper_band\", \"lower_band\", \"atr\", \"cmf\", \"%K_smooth\", \"%D\"]\n",
        "DISCORD_WEBHOOK_URL = \"\"\n",
        "ANOMALY_THRESHOLD = 0.0\n",
        "# New: Signal parameters with defaults\n",
        "TREND_WINDOW = 50\n",
        "RSI_BUY_THRESHOLD = 30\n",
        "RSI_SELL_THRESHOLD = 70\n",
        "# New: Variables for backtesting configuration\n",
        "INITIAL_CAPITAL = 10000\n",
        "COMMISSION_RATE = 0.001\n",
        "\n",
        "\n",
        "# ----------------------------------------------------\n",
        "\n",
        "def send_discord_message(text, webhook_url):\n",
        "    \"\"\"\n",
        "    Envia un mensaje a un canal de Discord usando un webhook con diagnóstico.\n",
        "    Si webhook_url está vacío, simplemente imprime un mensaje indicando que no se enviará.\n",
        "    \"\"\"\n",
        "    if not webhook_url:\n",
        "        print(\"Diagnóstico Discord: URL de Webhook no configurada. No se intentara enviar mensaje.\")\n",
        "        return\n",
        "\n",
        "    data = {\"content\": text}\n",
        "    try:\n",
        "        print(f\"Diagnóstico Discord: Intentando enviar mensaje a {webhook_url}...\")\n",
        "        response = requests.post(webhook_url, json=data)\n",
        "        response.raise_for_status() # Levanta una excepcion para codigos de estado HTTP de error (4xx o 5xx)\n",
        "        print(\"Diagnóstico Discord: Mensaje enviado exitosamente.\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Diagnóstico Discord: Error al enviar mensaje a Discord - {e}\")\n",
        "        if hasattr(e, 'response') and e.response is not None:\n",
        "            print(f\"Diagnóstico Discord: Código de estado HTTP - {e.response.status_code}\")\n",
        "            print(f\"Diagnóstico Discord: Cuerpo de la respuesta - {e.response.text}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Diagnóstico Discord: Ocurrio un error inesperado al enviar a Discord:\", e)\n",
        "\n",
        "\n",
        "def fetch_data(symbol, period, interval):\n",
        "    \"\"\"\n",
        "    Descarga los datos OHLCV de Yahoo Finance para un simbolo dado\n",
        "    y aplana el MultiIndex si existe, renombrando columnas para manejo consistente.\n",
        "    Incluye manejo de errores y diagnóstico si no se obtienen datos.\n",
        "    \"\"\"\n",
        "    print(f\"Descargando datos para: {symbol} (Periodo: {period}, Intervalo: {interval})\")\n",
        "    df = pd.DataFrame() # Inicializa un dataframe vacio\n",
        "\n",
        "    try:\n",
        "        # Use auto_adjust=True to get adjusted close price (Open, High, Low, Close)\n",
        "        df = yf.download(tickers=symbol, period=period, interval=interval, progress=False, threads=False, auto_adjust=True)\n",
        "\n",
        "        if df.empty:\n",
        "            print(f\"Diagnóstico Fetch: yfinance.download retornó un dataframe vacio para {symbol}. Esto puede deberse a:\")\n",
        "            print(\"- Símbolo incorrecto o no encontrado.\")\n",
        "            print(\"- Combinación de Periodo/Intervalo no soportada o sin datos disponibles.\")\n",
        "            print(\"- Problemas temporales con la fuente de datos (Yahoo Finance).\")\n",
        "            return pd.DataFrame() # Retorna un dataframe vacio si no hay datos\n",
        "\n",
        "        df = df.dropna() # Eliminar filas con valores faltantes despues de la descarga\n",
        "\n",
        "        if df.empty:\n",
        "             print(f\"Diagnóstico Fetch: El dataframe para {symbol} quedo vacio despues de eliminar NaNs. Puede que no haya suficientes datos limpios para el periodo/intervalo especificado.\")\n",
        "\n",
        "\n",
        "        # Handle MultiIndex from multiple symbols download (yfinance returns MultiIndex for >1 symbol)\n",
        "        # Use the global SYMBOLS list to determine if multiple symbols were requested initially\n",
        "        if isinstance(df.columns, pd.MultiIndex):\n",
        "            print(f\"Diagnóstico Fetch: Detectado MultiIndex para {symbol}. Aplanando columnas.\")\n",
        "            # Create new column names by joining levels (e.g., ('Close', 'AAPL') -> 'Close_AAPL')\n",
        "            # Ensure only relevant columns ('Open', 'High', 'Low', 'Close', 'Volume') are kept and renamed\n",
        "\n",
        "            # Select only the columns relevant to the current symbol based on the original MultiIndex structure\n",
        "            # This is a safer way to select columns for a specific symbol from a multi-symbol download MultiIndex\n",
        "            try:\n",
        "                # Ensure the MultiIndex has the expected levels and structure\n",
        "                # Check if the symbol is actually in the second level of the MultiIndex\n",
        "                if len(df.columns.levels) > 1 and symbol in df.columns.levels[1]:\n",
        "                    cols_to_select = [(col_type, symbol) for col_type in ['Open', 'High', 'Low', 'Close', 'Volume'] if (col_type, symbol) in df.columns]\n",
        "                    if cols_to_select:\n",
        "                         df_single_symbol = df[cols_to_select]\n",
        "                         # Rename the columns to single level names (e.g., ('Close', 'AAPL') -> 'Close')\n",
        "                         df_single_symbol.columns = [col[0] for col in df_single_symbol.columns.values]\n",
        "                         df = df_single_symbol # Replace the original df with the single symbol flat df\n",
        "                         print(f\"Diagnóstico Fetch: Columnas aplanadas y seleccionadas para {symbol}: {list(df.columns)}\")\n",
        "                    else:\n",
        "                         print(f\"Diagnóstico Fetch: No se encontraron columnas OHLCV/Volume con MultiIndex para el simbolo {symbol}.\")\n",
        "                         return pd.DataFrame()\n",
        "                else:\n",
        "                     print(f\"Diagnóstico Fetch: La estructura del MultiIndex no es la esperada para el simbolo {symbol} o el simbolo no esta en el MultiIndex.\")\n",
        "                     # Attempt to handle cases where yfinance might return a MultiIndex even for a single symbol in a different format\n",
        "                     if len(df.columns.levels) == 1 and len(df.columns) > 0:\n",
        "                          print(\"Diagnóstico Fetch: Intentando aplanar MultiIndex de un nivel.\")\n",
        "                          df.columns = [col[0] if isinstance(col, tuple) else col for col in df.columns.values]\n",
        "                          print(f\"Diagnóstico Fetch: Columnas aplanadas: {list(df.columns)}\")\n",
        "                     else:\n",
        "                          print(f\"Niveles del MultiIndex: {df.columns.levels}\")\n",
        "                          return pd.DataFrame()\n",
        "            except KeyError as e:\n",
        "                 print(f\"Diagnóstico Fetch: Error al seleccionar columnas para el simbolo {symbol} despues de MultiIndex: {e}\")\n",
        "                 print(f\"Columnas disponibles en el dataframe MultiIndex: {list(df.columns)}\")\n",
        "                 return pd.DataFrame()\n",
        "\n",
        "\n",
        "        # For single symbol download, yfinance might return a MultiIndex with one level, flatten that too\n",
        "        # Or simply rename the columns to standard names if not already\n",
        "        elif isinstance(df.columns, pd.MultiIndex) and len(df.columns.levels) > 0 and len(df.columns.levels[0]) > 0 and len(df.columns.levels[1]) == 1:\n",
        "             df.columns = [col[0] for col in df.columns.values]\n",
        "             print(f\"Diagnóstico Fetch: Detectado MultiIndex de un nivel para {symbol}. Aplanando columnas: {list(df.columns)}\")\n",
        "        # If it's already a flat index but column names are lowercase, normalize them\n",
        "        elif all(col.islower() for col in df.columns):\n",
        "            df.columns = [col.capitalize() for col in df.columns]\n",
        "            print(f\"Diagnóstico Fetch: Columnas en minusculas normalizadas para {symbol}: {list(df.columns)}\")\n",
        "        else:\n",
        "             print(f\"Diagnóstico Fetch: Columnas ya planas o no estandar para {symbol}: {list(df.columns)}\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Diagnóstico Fetch: Ocurrio un error inesperado durante la descarga de datos para {symbol}: {e}\")\n",
        "        return pd.DataFrame() # Retorna un dataframe vacio en caso de excepcion\n",
        "\n",
        "    if df.empty:\n",
        "        print(f\"Diagnóstico Fetch: El dataframe final para {symbol} esta vacio despues de procesar.\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def feature_engineer(df, symbol):\n",
        "    \"\"\"\n",
        "    Calcula caracteristicas (features) para la deteccion de anomalias,\n",
        "    incluyendo indicadores técnicos comunes como RSI, MACD, Bollinger Bands, ATR, CMF, y Stochastic Oscillator.\n",
        "    Asume que el dataframe tiene columnas aplanadas ('Open', 'High', 'Low', 'Close', 'Volume')\n",
        "    después de fetch_data, independientemente de si fue descarga de uno o múltiples símbolos.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Determine the correct column names - assuming fetch_data has normalized them to single level\n",
        "    close_col = \"Close\"\n",
        "    high_col = \"High\"\n",
        "    low_col = \"Low\"\n",
        "    volume_col = \"Volume\"\n",
        "\n",
        "    # Ensure the required columns exist before proceeding with calculations\n",
        "    required_cols = [close_col, high_col, low_col, volume_col]\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        print(f\"Error: Missing required columns for feature engineering for {symbol}.\")\n",
        "        print(f\"Expected: {required_cols}, Found: {list(df.columns)}\")\n",
        "        return pd.DataFrame() # Return empty DataFrame if essential columns are missing\n",
        "\n",
        "\n",
        "    # Retornos logaritmicos: Mide el cambio porcentual en el precio en una escala logaritmica.\n",
        "    df[\"logret\"] = np.log(df[close_col] / df[close_col].shift(1))\n",
        "    # Volatilidad realizada (usando una ventana mas pequeña para mayor sensibilidad)\n",
        "    # Mide la dispersion de los retornos en un periodo corto (10 periodos).\n",
        "    df[\"vol_10\"] = df[\"logret\"].rolling(window=10).std() * np.sqrt(252)\n",
        "    # Volatilidad realizada anualizada (ventana mas grande)\n",
        "    # Mide la dispersion de los retornos en un periodo mas largo (20 periodos), anualizada.\n",
        "    df[\"vol_20\"] = df[\"logret\"].rolling(window=20).std() * np.sqrt(252)\n",
        "    # Z-score del precio (desviacion del precio respecto a su media movil)\n",
        "    # Indica cuantas desviaciones estandar esta el precio actual de su media movil de 20 periodos.\n",
        "    df[\"z_price\"] = (df[close_col] - df[close_col].rolling(20).mean()) / df[close_col].rolling(20).std()\n",
        "    # Z-score del volumen (desviacion del volumen respecto a su media movil)\n",
        "    # Indica cuantas desviaciones estandar esta el volumen actual de su media movil de 20 periodos.\n",
        "    df[\"vol_z\"] = (df[volume_col] - df[volume_col].rolling(20).mean()) / df[volume_col].rolling(20).std()\n",
        "    # Interaccion entre precio y volumen (puede indicar movimientos inusuales)\n",
        "    # Combina el cambio de precio con la desviacion del volumen para identificar eventos donde\n",
        "    # grandes cambios de precio ocurren con volumen inusual.\n",
        "    df[\"price_vol_interaction\"] = df[\"logret\"] * df[\"vol_z\"]\n",
        "    # Media movil del logret para capturar tendencias a corto plazo\n",
        "    # Suaviza los retornos logaritmicos para identificar la direccion promedio del movimiento.\n",
        "    df[\"logret_ma5\"] = df[\"logret\"].rolling(window=5).mean()\n",
        "\n",
        "    # Calcular RSI (Relative Strength Index): Indicador de momentum que mide la velocidad y cambio de los movimientos de precios.\n",
        "    # Window for RSI (commonly 14 periods)\n",
        "    rsi_window = 14\n",
        "    delta = df[close_col].diff()\n",
        "    gain = delta.where(delta > 0, 0)\n",
        "    loss = -delta.where(delta < 0, 0)\n",
        "    avg_gain = gain.ewm(com=rsi_window - 1, adjust=False).mean()\n",
        "    avg_loss = loss.ewm(com=rsi_window - 1, adjust=False).mean()\n",
        "    # Avoid division by zero\n",
        "    rs = avg_gain / (avg_loss + 1e-10)\n",
        "    df[\"rsi\"] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # Calcular MACD (Moving Average Convergence Divergence): Indicador de seguimiento de tendencia que muestra la relacion entre dos medias moviles del precio de un activo.\n",
        "    # EMA windows for MACD (commonly 12, 26, 9 periods)\n",
        "    ema_fast_window = 12\n",
        "    ema_slow_window = 26\n",
        "    signal_window = 9\n",
        "    ema_fast = df[close_col].ewm(span=ema_fast_window, adjust=False).mean()\n",
        "    ema_slow = df[close_col].ewm(span=ema_slow_window, adjust=False).mean()\n",
        "    df[\"macd\"] = ema_fast - ema_slow # Linea MACD\n",
        "    df[\"macd_signal\"] = df[\"macd\"].ewm(span=signal_window, adjust=False).mean() # Linea de señal\n",
        "    df[\"macd_hist\"] = df[\"macd\"] - df[\"macd_signal\"] # Histograma MACD\n",
        "\n",
        "    # Calcular Bollinger Bands: Indicadores de volatilidad que se basan en una media móvil simple y dos bandas de desviación estándar.\n",
        "    bb_window = 20\n",
        "    df['rolling_mean'] = df[close_col].rolling(window=bb_window).mean()\n",
        "    df['rolling_std'] = df[close_col].rolling(window=bb_window).std()\n",
        "    df['upper_band'] = df['rolling_mean'] + (df['rolling_std'] * 2)\n",
        "    df['lower_band'] = df['rolling_mean'] - (df['rolling_std'] * 2)\n",
        "\n",
        "\n",
        "    # Calcular Average True Range (ATR): Mide la volatilidad del mercado.\n",
        "    atr_window = 14\n",
        "    # Calculate True Range (TR)\n",
        "    df['tr1'] = abs(df[high_col] - df[low_col])\n",
        "    df['tr2'] = abs(df[high_col] - df[close_col].shift(1))\n",
        "    df['tr3'] = abs(df[low_col] - df[close_col].shift(1))\n",
        "    df['tr'] = df[['tr1', 'tr2', 'tr3']].max(axis=1)\n",
        "    # Calculate ATR using Exponential Moving Average (EMA)\n",
        "    df['atr'] = df['tr'].ewm(span=atr_window, adjust=False).mean()\n",
        "\n",
        "\n",
        "    # Calcular Chaikin Money Flow (CMF): Combina precio y volumen para medir la presión de compra y venta.\n",
        "    cmf_window = 20\n",
        "    # Calculate Money Flow Volume (MFV)\n",
        "    # Avoid division by zero\n",
        "    df['mf_multiplier'] = ((df[close_col] - df[low_col]) - (df[high_col] - df[close_col])) / (df[high_col] - df[low_col] + 1e-10)\n",
        "\n",
        "    # Ensure multiplication with the correct Volume column and assign to a single column 'mfv'\n",
        "    # Check if the volume_col exists in the DataFrame before accessing\n",
        "    if volume_col in df.columns:\n",
        "        df['mfv'] = df['mf_multiplier'] * df[volume_col]\n",
        "        # Calculate CMF\n",
        "        # Ensure sum is calculated over the correct 'mfv' column\n",
        "        # Avoid division by zero if the sum of volume is zero\n",
        "        volume_sum_rolling = df[volume_col].rolling(window=cmf_window).sum()\n",
        "        df['cmf'] = df['mfv'].rolling(window=cmf_window).sum() / (volume_sum_rolling + 1e-10)\n",
        "    else:\n",
        "        print(f\"Warning: Volume column '{volume_col}' not found for CMF calculation for {symbol}.\")\n",
        "        df['mfv'] = np.nan\n",
        "        df['cmf'] = np.nan\n",
        "\n",
        "    # Calcular Stochastic Oscillator: Indicador de momentum que compara el precio de cierre particular con un rango de sus precios durante un período de tiempo determinado.\n",
        "    stoch_window = 14\n",
        "    stoch_smooth_k = 3\n",
        "    stoch_smooth_d = 3\n",
        "\n",
        "    # Ensure High and Low columns exist for Stochastic calculation\n",
        "    if high_col in df.columns and low_col in df.columns:\n",
        "        # Calculate Lowest Low (LL) and Highest High (HH) over the window\n",
        "        df['LL'] = df[low_col].rolling(window=stoch_window).min()\n",
        "        df['HH'] = df[high_col].rolling(window=stoch_window).max()\n",
        "\n",
        "        # Calculate %K\n",
        "        # Avoid division by zero if HH equals LL\n",
        "        df['%K'] = ((df[close_col] - df['LL']) / (df['HH'] - df['LL'] + 1e-10)) * 100\n",
        "\n",
        "        # Calculate %D (Simple Moving Average of %K)\n",
        "        df['%D'] = df['%K'].rolling(window=stoch_smooth_d).mean()\n",
        "\n",
        "        # Smooth %K (optional, but common)\n",
        "        df['%K_smooth'] = df['%K'].rolling(window=stoch_smooth_k).mean()\n",
        "\n",
        "        # Drop temporary columns\n",
        "        df = df.drop(columns=['LL', 'HH'], errors='ignore')\n",
        "    else:\n",
        "        print(f\"Warning: High or Low columns not found for Stochastic Oscillator calculation for {symbol}.\")\n",
        "        df['%K'] = np.nan\n",
        "        df['%D'] = np.nan\n",
        "        df['%K_smooth'] = np.nan\n",
        "\n",
        "\n",
        "    # Clean up temporary columns at the very end\n",
        "    # Use a list comprehension to ensure only existing columns are dropped\n",
        "    cols_to_drop = ['rolling_mean', 'rolling_std', 'tr1', 'tr2', 'tr3', 'tr', 'mf_multiplier', 'mfv']\n",
        "    df = df.drop(columns=[col for col in cols_to_drop if col in df.columns], errors='ignore')\n",
        "\n",
        "\n",
        "    df = df.dropna() # Eliminar filas con valores NaN generados por los calculos de ventanas moviles y EMA\n",
        "    return df\n",
        "\n",
        "def detect_rules(df, z_threshold):\n",
        "    \"\"\"\n",
        "    Aplica reglas simples basadas en umbrales de z-score.\n",
        "    \"\"\"\n",
        "    # Ensure z_price and vol_z exist before accessing\n",
        "    if 'z_price' not in df.columns or 'vol_z' not in df.columns:\n",
        "        print(\"Error: Columnas 'z_price' o 'vol_z' faltantes para aplicar reglas.\")\n",
        "        df[\"rule_price_z\"] = False\n",
        "        df[\"rule_vol_spike\"] = False\n",
        "        df[\"rule_combo\"] = False\n",
        "        return df\n",
        "\n",
        "    # Indicadores basados en reglas: Identifica puntos donde el Z-score del precio o volumen supera un umbral definido.\n",
        "    df[\"rule_price_z\"] = df[\"z_price\"].abs() > z_threshold\n",
        "    df[\"rule_vol_spike\"] = df[\"vol_z\"] > z_threshold # Solo consideramos picos de volumen (vol_z positivo)\n",
        "    # Combinacion de reglas (ambas condiciones se cumplen): Identifica puntos que cumplen ambas reglas simultaneamente.\n",
        "    df[\"rule_combo\"] = df[\"rule_price_z\"] & df[\"rule_vol_spike\"]\n",
        "    return df\n",
        "\n",
        "def fit_isolationforest(df, features, contamination):\n",
        "    \"\"\"\n",
        "    Entrena y aplica el modelo Isolation Forest para la deteccion de anomalias.\n",
        "    Isolation Forest aisla las anomalias en lugar de perfilar los puntos normales.\n",
        "    \"\"\"\n",
        "    # Aseguramos que solo usamos las features definidas y manejamos NaNs (rellenando con 0, considerar otras estrategias si es necesario)\n",
        "    # Filter features to only include those present in the DataFrame columns and are strings\n",
        "    available_features = [f for f in features if isinstance(f, str) and f in df.columns]\n",
        "    if not available_features:\n",
        "        print(\"Error: No available features (o nombres de features invalidos) para Isolation Forest training.\")\n",
        "        df[\"if_score\"] = np.nan\n",
        "        df[\"if_score_norm\"] = np.nan\n",
        "        return df, None # Return df and None model if no features\n",
        "\n",
        "    X = df[available_features].fillna(0).values\n",
        "    # Ensure X is not empty after filtering features and handling NaNs\n",
        "    if X.size == 0 or X.shape[0] == 0:\n",
        "        print(\"Error: Features matrix is empty after filtering. Cannot train Isolation Forest.\")\n",
        "        df[\"if_score\"] = np.nan\n",
        "        df[\"if_score_norm\"] = np.nan\n",
        "        return df, None\n",
        "\n",
        "    try:\n",
        "        model = IsolationForest(n_estimators=200, contamination=contamination, random_state=42)\n",
        "        model.fit(X)\n",
        "        # Puntuacion de anomalia (mayor puntuacion -> mas anomalo)\n",
        "        # Los valores mas bajos de decision_function indican mas anomalias. Se invierte para que un valor mas alto signifique mas anomalia.\n",
        "        scores = -model.decision_function(X)\n",
        "        df[\"if_score\"] = scores\n",
        "        # Normalizar la puntuacion entre 0 y 1 para combinarla con otras metricas mas facilmente.\n",
        "        # Avoid division by zero if max and min are the same\n",
        "        score_min = df[\"if_score\"].min()\n",
        "        score_max = df[\"if_score\"].max()\n",
        "        score_range = score_max - score_min\n",
        "\n",
        "        df[\"if_score_norm\"] = (df[\"if_score\"] - score_min) / (score_range + 1e-9) if score_range != 0 else 0\n",
        "        return df, model\n",
        "    except Exception as e:\n",
        "        print(f\"Error durante el entrenamiento/aplicacion de Isolation Forest: {e}\")\n",
        "        df[\"if_score\"] = np.nan\n",
        "        df[\"if_score_norm\"] = np.nan\n",
        "        return df, None # Return df and None model in case of error\n",
        "\n",
        "\n",
        "def combined_score(df):\n",
        "    \"\"\"\n",
        "    Calcula un score combinado a partir de los diferentes metodos de deteccion (Isolation Forest, reglas).\n",
        "    \"\"\"\n",
        "    # Ensure z_price and vol_z exist before accessing\n",
        "    if 'z_price' not in df.columns or 'vol_z' not in df.columns:\n",
        "        print(\"Error: Columnas 'z_price' o 'vol_z' faltantes para calcular el score combinado.\")\n",
        "        df[\"final_score\"] = np.nan\n",
        "        return df\n",
        "\n",
        "\n",
        "    # Ensemble simple ponderado: Combina la puntuacion normalizada de IF con las puntuaciones normalizadas de los indicadores de reglas.\n",
        "    # Normalizamos las caracteristicas usadas en las reglas para combinarlas\n",
        "    z = df[\"z_price\"].abs() # Valor absoluto del Z-score del precio\n",
        "    zv = df[\"vol_z\"].clip(lower=0)  # Solo consideramos picos de volumen positivos\n",
        "\n",
        "    # Evitamos division por cero si el rango es 0\n",
        "    z_min, z_max = z.min(), z.max()\n",
        "    zv_min, zv_max = zv.min(), zv.max()\n",
        "\n",
        "    # Ensure z_max and zv_max are not equal to z_min and zv_min respectively to avoid division by zero\n",
        "    z_range = z_max - z_min\n",
        "    zv_range = zv_max - zv_min\n",
        "\n",
        "    df[\"z_norm\"] = (z - z_min) / (z_range + 1e-9) if z_range != 0 else 0 # Normalizacion del Z-score del precio, handle zero range\n",
        "    df[\"vol_norm\"] = (zv - zv_min) / (zv_range + 1e-9) if zv_range != 0 else 0 # Normalizacion del Z-score del volumen normalizado (solo picos), handle zero range\n",
        "\n",
        "\n",
        "    # Ponderacion de los scores: Asigna pesos a cada componente del score combinado.\n",
        "    # Los pesos pueden ser ajustados para dar mas importancia a un metodo u otro.\n",
        "    # Ensure if_score_norm is not None before using\n",
        "    if 'if_score_norm' in df.columns and pd.notna(df['if_score_norm']).any():\n",
        "         df[\"final_score\"] = (0.5 * df[\"if_score_norm\"] + # 50% del score de Isolation Forest\n",
        "                              0.3 * df[\"z_norm\"] +        # 30% del score Z-score del precio normalizado\n",
        "                              0.2 * df[\"vol_norm\"])       # 20% del score Z-score del volumen normalizado\n",
        "    else:\n",
        "         print(\"Advertencia: if_score_norm no disponible o contiene solo NaNs. Usando score combinado basado solo en reglas.\")\n",
        "         df[\"final_score\"] = (0.3 * df[\"z_norm\"] +\n",
        "                              0.2 * df[\"vol_norm\"]) # Fallback score if IF failed or has no valid scores\n",
        "\n",
        "\n",
        "    return df\n",
        "\n",
        "def generate_signals(df, signal_anomaly_threshold, symbol, trend_window=50, rsi_buy_threshold=30, rsi_sell_threshold=70):\n",
        "    \"\"\"\n",
        "    Genera señales de compra/venta mas sofisticadas.\n",
        "    Considera:\n",
        "    - Score de anomalia combinado.\n",
        "    - Direccion de la tendencia (basado en una media movil).\n",
        "    - Valores de indicadores tecnicos especificos (ej. RSI).\n",
        "    Añade columnas 'buy_signal' y 'sell_signal' al dataframe.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Initialize signal columns to False\n",
        "    df['buy_signal'] = False\n",
        "    df['sell_signal'] = False\n",
        "\n",
        "    # Determine the correct 'Close' column name - should be 'Close' after flattening\n",
        "    close_col_name = \"Close\"\n",
        "\n",
        "    if close_col_name not in df.columns:\n",
        "         print(f\"Advertencia: No se encontró la columna '{close_col_name}' para generar señales de trading para {symbol}. Columnas disponibles: {list(df.columns)}\")\n",
        "         return df # Return dataframe without signals\n",
        "\n",
        "    # --- Sophisticated Signal Logic ---\n",
        "\n",
        "    # 1. Trend Analysis (using a Simple Moving Average)\n",
        "    # Calculate the moving average\n",
        "    df['trend_ma'] = df[close_col_name].rolling(window=trend_window).mean()\n",
        "\n",
        "    # Determine trend direction (price above MA = uptrend, price below MA = downtrend)\n",
        "    df['is_uptrend'] = df[close_col_name] > df['trend_ma']\n",
        "    df['is_downtrend'] = df[close_col_name] < df['trend_ma']\n",
        "\n",
        "    # 2. Combine Anomaly Score, Trend, and Indicator Conditions (e.g., RSI)\n",
        "    # Ensure 'final_score' and 'rsi' columns exist\n",
        "    if 'final_score' in df.columns and pd.notna(df['final_score']).any() and 'rsi' in df.columns and pd.notna(df['rsi']).any():\n",
        "\n",
        "        # Buy signal: High anomaly score AND (is_uptrend OR price is starting to move up) AND (RSI is oversold OR moving upwards from oversold)\n",
        "        # A simplified example: High anomaly score AND Uptrend AND RSI is below a threshold\n",
        "        df.loc[\n",
        "            (df['final_score'] > signal_anomaly_threshold) &\n",
        "            (df['is_uptrend'] == True) &\n",
        "            (df['rsi'] < rsi_buy_threshold),\n",
        "            'buy_signal'\n",
        "        ] = True\n",
        "\n",
        "        # Sell signal: High anomaly score AND (is_downtrend OR price is starting to move down) AND (RSI is overbought OR moving downwards from overbought)\n",
        "        # A simplified example: High anomaly score AND Downtrend AND RSI is above a threshold\n",
        "        df.loc[\n",
        "            (df['final_score'] > signal_anomaly_threshold) &\n",
        "            (df['is_downtrend'] == True) &\n",
        "            (df['rsi'] > rsi_sell_threshold),\n",
        "            'sell_signal'\n",
        "        ] = True\n",
        "\n",
        "    else:\n",
        "         print(\"Advertencia: Columna 'final_score' o 'rsi' no disponible/contiene NaNs. No se pueden generar señales basadas en el score de anomalia y RSI.\")\n",
        "\n",
        "\n",
        "    # Clean up temporary columns used for signaling logic if desired\n",
        "    df = df.drop(columns=['trend_ma', 'is_uptrend', 'is_downtrend'], errors='ignore')\n",
        "\n",
        "\n",
        "    # Note: This is a basic example. More complex logic could involve:\n",
        "    # - Using different types of moving averages (EMA, etc.)\n",
        "    # - Considering crossovers of MAs\n",
        "    # - Incorporating other indicators (MACD crossovers, volume surges not captured by vol_z, etc.)\n",
        "    # - Implementing entry/exit logic (e.g., buy signal starts a potential trade, sell signal exits it)\n",
        "\n",
        "    return df # Return dataframe with added signal columns\n",
        "\n",
        "# --- Backtesting Module ---\n",
        "\n",
        "def backtest_strategy(df, initial_capital=10000, commission_rate=0.001):\n",
        "    \"\"\"\n",
        "    Simula la ejecucion de una estrategia de trading basada en señales de compra/venta.\n",
        "    Calcula metricas de rendimiento como P/L, numero de operaciones, tasa de exito, etc.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame con datos de precios y señales ('Close', 'buy_signal', 'sell_signal').\n",
        "        initial_capital (float): Capital inicial para la simulacion.\n",
        "        commission_rate (float): Tasa de comision por operacion (ej. 0.001 para 0.1%).\n",
        "\n",
        "    Returns:\n",
        "        dict: Un diccionario que contiene las metricas de backtesting.\n",
        "    \"\"\"\n",
        "    if df is None or df.empty:\n",
        "        print(\"Error: DataFrame vacio o nulo proporcionado para backtesting.\")\n",
        "        return None\n",
        "\n",
        "    if 'Close' not in df.columns or 'buy_signal' not in df.columns or 'sell_signal' not in df.columns:\n",
        "        print(\"Error: DataFrame no contiene las columnas necesarias ('Close', 'buy_signal', 'sell_signal') para backtesting.\")\n",
        "        return None\n",
        "\n",
        "    # Initialize variables for backtesting\n",
        "    capital = initial_capital\n",
        "    position = 0  # 0: No position, 1: Long position\n",
        "    trades = []\n",
        "    entry_price = 0\n",
        "    peak_capital = initial_capital\n",
        "    max_drawdown = 0\n",
        "\n",
        "    # Iterate through the dataframe to simulate trades\n",
        "    for i in range(len(df)):\n",
        "        # Get current data point\n",
        "        current_price = df['Close'].iloc[i]\n",
        "        buy_signal = df['buy_signal'].iloc[i]\n",
        "        sell_signal = df['sell_signal'].iloc[i]\n",
        "        current_date = df.index[i]\n",
        "\n",
        "        # --- Trading Logic ---\n",
        "\n",
        "        # Check for Buy Signal and if not already in a position\n",
        "        if buy_signal and position == 0:\n",
        "            # Calculate maximum shares to buy with available capital\n",
        "            # Consider commission: price * shares * (1 + commission_rate) <= capital\n",
        "            # shares <= capital / (price * (1 + commission_rate))\n",
        "            max_shares = capital / (current_price * (1 + commission_rate))\n",
        "            shares_to_buy = int(max_shares) # Buy whole shares\n",
        "\n",
        "            if shares_to_buy > 0:\n",
        "                 cost = shares_to_buy * current_price * (1 + commission_rate)\n",
        "                 capital -= cost\n",
        "                 position = shares_to_buy\n",
        "                 entry_price = current_price\n",
        "                 print(f\"{current_date.strftime('%Y-%m-%d %H:%M:%S')} - BUY: {shares_to_buy} shares at {current_price:.2f}. Capital remaining: {capital:.2f}\")\n",
        "\n",
        "\n",
        "        # Check for Sell Signal and if in a long position\n",
        "        elif sell_signal and position > 0:\n",
        "            # Calculate proceeds from selling\n",
        "            proceeds = position * current_price * (1 - commission_rate)\n",
        "            profit_loss = proceeds - (position * entry_price * (1 + commission_rate)) # Calculate P/L based on entry cost including commission\n",
        "            capital += proceeds\n",
        "\n",
        "            trades.append({\n",
        "                'entry_date': df.index[df['Close'] == entry_price].max(), # Find date of entry price (might not be exact match, find closest or use index)\n",
        "                'exit_date': current_date,\n",
        "                'entry_price': entry_price,\n",
        "                'exit_price': current_price,\n",
        "                'shares': position,\n",
        "                'profit_loss': profit_loss,\n",
        "                'trade_type': 'Long' # Only long trades in this simple strategy\n",
        "            })\n",
        "\n",
        "            print(f\"{current_date.strftime('%Y-%m-%d %H:%M:%S')} - SELL: {position} shares at {current_price:.2f}. P/L: {profit_loss:.2f}. Capital: {capital:.2f}\")\n",
        "\n",
        "            # Reset position\n",
        "            position = 0\n",
        "            entry_price = 0\n",
        "\n",
        "        # --- Capital Tracking and Drawdown Calculation ---\n",
        "        current_portfolio_value = capital + (position * current_price)\n",
        "        peak_capital = max(peak_capital, current_portfolio_value)\n",
        "        drawdown = (peak_capital - current_portfolio_value) / peak_capital if peak_capital > 0 else 0\n",
        "        max_drawdown = max(max_drawdown, drawdown)\n",
        "\n",
        "\n",
        "    # Close any open position at the end of the data\n",
        "    if position > 0:\n",
        "        current_price = df['Close'].iloc[-1]\n",
        "        current_date = df.index[-1]\n",
        "        proceeds = position * current_price * (1 - commission_rate)\n",
        "        profit_loss = proceeds - (position * entry_price * (1 + commission_rate))\n",
        "        capital += proceeds\n",
        "\n",
        "        trades.append({\n",
        "            'entry_date': df.index[df['Close'] == entry_price].max(),\n",
        "            'exit_date': current_date,\n",
        "            'entry_price': entry_price,\n",
        "            'exit_price': current_price,\n",
        "            'shares': position,\n",
        "            'profit_loss': profit_loss,\n",
        "            'trade_type': 'Long'\n",
        "        })\n",
        "        print(f\"{current_date.strftime('%Y-%m-%d %H:%M:%S')} - FINAL SELL: {position} shares at {current_price:.2f}. P/L: {profit_loss:.2f}. Final Capital: {capital:.2f}\")\n",
        "\n",
        "\n",
        "    # --- Calculate Backtesting Metrics ---\n",
        "    total_profit_loss = capital - initial_capital\n",
        "    num_trades = len(trades)\n",
        "    winning_trades = [trade for trade in trades if trade['profit_loss'] > 0]\n",
        "    losing_trades = [trade for trade in trades if trade['profit_loss'] <= 0] # Includes zero profit trades as non-winners\n",
        "\n",
        "    win_rate = len(winning_trades) / num_trades if num_trades > 0 else 0\n",
        "    total_winning_profit = sum(trade['profit_loss'] for trade in winning_trades)\n",
        "    total_losing_loss = sum(trade['profit_loss'] for trade in losing_trades)\n",
        "\n",
        "    avg_profit_per_winning_trade = total_winning_profit / len(winning_trades) if len(winning_trades) > 0 else 0\n",
        "    avg_loss_per_losing_trade = total_losing_loss / len(losing_trades) if len(losing_trades) > 0 else 0 # This will be negative or zero\n",
        "\n",
        "    # Profit Factor: Total Gross Profit / Total Gross Loss (Absolute value)\n",
        "    # Avoid division by zero if there are no losing trades\n",
        "    profit_factor = total_winning_profit / abs(total_losing_loss) if total_losing_loss < 0 else (total_winning_profit if total_losing_loss == 0 else np.nan) # Handle cases with no losses or zero losses\n",
        "\n",
        "\n",
        "    backtest_results = {\n",
        "        'initial_capital': initial_capital,\n",
        "        'final_capital': capital,\n",
        "        'total_profit_loss': total_profit_loss,\n",
        "        'return_percentage': (total_profit_loss / initial_capital) * 100 if initial_capital > 0 else 0,\n",
        "        'num_trades': num_trades,\n",
        "        'win_rate': win_rate,\n",
        "        'total_winning_profit': total_winning_profit,\n",
        "        'total_losing_loss': total_losing_loss,\n",
        "        'avg_profit_per_winning_trade': avg_profit_per_winning_trade,\n",
        "        'avg_loss_per_losing_trade': avg_loss_per_losing_trade,\n",
        "        'profit_factor': profit_factor,\n",
        "        'max_drawdown': max_drawdown,\n",
        "        'trades': trades # Optionally include the list of individual trades\n",
        "    }\n",
        "\n",
        "    return backtest_results\n",
        "\n",
        "\n",
        "def run_anomaly_detection(symbol, period, interval, z_threshold, if_contamination, if_features, anomaly_threshold, trend_window=50, rsi_buy_threshold=30, rsi_sell_threshold=70):\n",
        "    \"\"\"\n",
        "    Ejecuta el proceso completo de deteccion de anomalias para un simbolo.\n",
        "    Retorna el dataframe procesado con resultados de anomalias y señales.\n",
        "    (No envia mensaje de Discord aqui, eso se hace en el main interactivo)\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Procesando simbolo: {symbol} ---\")\n",
        "    df = fetch_data(symbol, period, interval)\n",
        "    if df is None or df.empty: # Check for None or empty df from fetch_data\n",
        "        print(f\"Saltando procesamiento para {symbol} debido a falta de datos.\")\n",
        "        return None # Return None if no data or error in fetch_data\n",
        "\n",
        "    df = feature_engineer(df, symbol) # Pass symbol to feature_engineer\n",
        "    if df.empty: # Check if feature engineering returned empty\n",
        "        print(f\"Saltando procesamiento para {symbol} debido a falta de datos despues de feature engineering.\")\n",
        "        return None\n",
        "\n",
        "    df = detect_rules(df, z_threshold)\n",
        "    # Aseguramos que el dataframe no esta vacio despues del feature engineering\n",
        "    if df.empty:\n",
        "         print(f\"Saltando procesamiento para {symbol} debido a falta de datos despues de deteccion por reglas.\")\n",
        "         return None\n",
        "\n",
        "    df, if_model = fit_isolationforest(df, if_features, if_contamination)\n",
        "    if df is None or df.empty: # Check if Isolation Forest returned empty or None model\n",
        "        print(f\"Saltando procesamiento para {symbol} debido a error o falta de datos despues de Isolation Forest.\")\n",
        "        return None\n",
        "\n",
        "    df = combined_score(df)\n",
        "    if df.empty: # Check if combined scoring returned empty\n",
        "        print(f\"Saltando procesamiento para {symbol} debido a falta de datos despues de calculo de score combinado.\")\n",
        "        return None\n",
        "\n",
        "    # Add signal generation logic - Pass the new parameters\n",
        "    df = generate_signals(df, anomaly_threshold, symbol, trend_window, rsi_buy_threshold, rsi_sell_threshold) # Use the main ANOMALY_THRESHOLD for signals and pass symbol, plus new params\n",
        "    if df.empty: # Check if signal generation returned empty\n",
        "        print(f\"Saltando procesamiento para {symbol} debido a falta de datos despues de generacion de señales.\")\n",
        "        return None\n",
        "\n",
        "    # Obtenemos el ultimo punto de datos para el resumen\n",
        "    # Ensure dataframe is not empty before accessing iloc[-1]\n",
        "    if df.empty:\n",
        "        latest = None\n",
        "    else:\n",
        "         latest = df.iloc[-1]\n",
        "\n",
        "\n",
        "    # Summarize results for the latest point\n",
        "    if latest is not None:\n",
        "        score = latest.get(\"final_score\", pd.Series([np.nan])).item()\n",
        "        rule_combo_status = bool(latest.get(\"rule_combo\", False))\n",
        "        buy_signal_latest = bool(latest.get('buy_signal', False))\n",
        "        sell_signal_latest = bool(latest.get('sell_signal', False))\n",
        "\n",
        "        print(f\"\\nResumen para el ultimo punto de {symbol}:\")\n",
        "        print(f\"Score Combinado: {score:.3f}\" if pd.notna(score) else \"Score Combinado: N/A\")\n",
        "        print(f\"Regla combinada activa: {rule_combo_status}\")\n",
        "        print(f\"Señal de compra: {buy_signal_latest}\")\n",
        "        print(f\"Señal de venta: {sell_signal_latest}\")\n",
        "\n",
        "        # Check for alert condition for the last point processed\n",
        "        if (pd.notna(score) and score > anomaly_threshold) or rule_combo_status or buy_signal_latest or sell_signal_latest:\n",
        "             print(f\"\\n¡ALERTA detectada para {symbol} en el último punto procesado!\")\n",
        "        else:\n",
        "             print(f\"\\nNo hay ALERTA para {symbol} en el último punto procesado.\")\n",
        "\n",
        "\n",
        "    return df # Return the processed dataframe\n",
        "\n",
        "# --- Main Execution with Interactive Menu ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- Bot de Detección de Anomalías y Señales ---\")\n",
        "\n",
        "    # Declare global variables first\n",
        "    global SYMBOLS\n",
        "    global PERIOD\n",
        "    global INTERVAL\n",
        "    global Z_THRESHOLD\n",
        "    global IF_CONTAMINATION\n",
        "    global IF_FEATURES\n",
        "    global DISCORD_WEBHOOK_URL\n",
        "    global ANOMALY_THRESHOLD\n",
        "    global TREND_WINDOW\n",
        "    global RSI_BUY_THRESHOLD\n",
        "    global RSI_SELL_THRESHOLD\n",
        "    global INITIAL_CAPITAL\n",
        "    global COMMISSION_RATE\n",
        "\n",
        "\n",
        "    # New: Ask user if they want to load configuration from a file\n",
        "    load_config_choice = input(\"¿Desea cargar la configuracion desde un archivo (ej. config.json)? (s/n): \").lower()\n",
        "    config_loaded = False\n",
        "\n",
        "    # Define variables with defaults (moved assignment after global declaration)\n",
        "    SYMBOLS = [\"BTC-USD\", \"ETH-USD\"]\n",
        "    PERIOD = \"30d\"\n",
        "    INTERVAL = \"5m\"\n",
        "    Z_THRESHOLD = 3.0\n",
        "    IF_CONTAMINATION = 0.01\n",
        "    IF_FEATURES = [\"logret\", \"vol_20\", \"z_price\", \"vol_z\", \"price_vol_interaction\", \"rsi\", \"macd\", \"upper_band\", \"lower_band\", \"atr\", \"cmf\", \"%K_smooth\", \"%D\"]\n",
        "    DISCORD_WEBHOOK_URL = \"\"\n",
        "    ANOMALY_THRESHOLD = 0.6\n",
        "    TREND_WINDOW = 50\n",
        "    RSI_BUY_THRESHOLD = 30\n",
        "    RSI_SELL_THRESHOLD = 70\n",
        "    INITIAL_CAPITAL = 10000\n",
        "    COMMISSION_RATE = 0.001\n",
        "\n",
        "\n",
        "    if load_config_choice == 's':\n",
        "        config_file_path = input(\"Ingrese la ruta del archivo de configuracion (dejar en blanco para 'config.json'): \") or \"config.json\"\n",
        "        try:\n",
        "            print(f\"Intentando cargar configuracion desde '{config_file_path}'...\")\n",
        "            with open(config_file_path, 'r') as f:\n",
        "                config = json.load(f)\n",
        "\n",
        "            # Update global configuration variables with values from the loaded dictionary\n",
        "            # Use .get() with default values to handle missing keys gracefully\n",
        "            # Ensure types are correct (e.g., float for thresholds, list for symbols/features)\n",
        "\n",
        "            SYMBOLS = [s.strip() for s in config.get(\"SYMBOLS\", \"\").split(',') if s.strip()] if isinstance(config.get(\"SYMBOLS\"), str) else SYMBOLS\n",
        "\n",
        "\n",
        "            PERIOD = config.get(\"PERIOD\", PERIOD)\n",
        "\n",
        "\n",
        "            INTERVAL = config.get(\"INTERVAL\", INTERVAL)\n",
        "\n",
        "\n",
        "            Z_THRESHOLD = float(config.get(\"Z_THRESHOLD\", Z_THRESHOLD)) if isinstance(config.get(\"Z_THRESHOLD\"), (int, float, str)) else Z_THRESHOLD\n",
        "\n",
        "\n",
        "            IF_CONTAMINATION = float(config.get(\"IF_CONTAMINATION\", IF_CONTAMINATION)) if isinstance(config.get(\"IF_CONTAMINATION\"), (int, float, str)) else IF_CONTAMINATION\n",
        "\n",
        "\n",
        "            # Expect IF_FEATURES to be a list in JSON, fallback to default string if not list\n",
        "            if isinstance(config.get(\"IF_FEATURES\"), list):\n",
        "                IF_FEATURES = [f.strip() for f in config.get(\"IF_FEATURES\") if isinstance(f, str) and f.strip()]\n",
        "            elif isinstance(config.get(\"IF_FEATURES\"), str):\n",
        "                IF_FEATURES = [f.strip() for f in config.get(\"IF_FEATURES\").split(',') if f.strip()]\n",
        "            else:\n",
        "                 IF_FEATURES = IF_FEATURES\n",
        "\n",
        "\n",
        "            DISCORD_WEBHOOK_URL = config.get(\"DISCORD_WEBHOOK_URL\", DISCORD_WEBHOOK_URL)\n",
        "\n",
        "\n",
        "            ANOMALY_THRESHOLD = float(config.get(\"ANOMALY_THRESHOLD\", ANOMALY_THRESHOLD)) if isinstance(config.get(\"ANOMALY_THRESHOLD\"), (int, float, str)) else ANOMALY_THRESHOLD\n",
        "\n",
        "            # New: Load signal parameters from config\n",
        "\n",
        "            TREND_WINDOW = int(config.get(\"TREND_WINDOW\", TREND_WINDOW)) if isinstance(config.get(\"TREND_WINDOW\"), (int, str)) else TREND_WINDOW\n",
        "\n",
        "\n",
        "            RSI_BUY_THRESHOLD = float(config.get(\"RSI_BUY_THRESHOLD\", RSI_BUY_THRESHOLD)) if isinstance(config.get(\"RSI_BUY_THRESHOLD\"), (int, float, str)) else RSI_BUY_THRESHOLD\n",
        "\n",
        "\n",
        "            RSI_SELL_THRESHOLD = float(config.get(\"RSI_SELL_THRESHOLD\", RSI_SELL_THRESHOLD)) if isinstance(config.get(\"RSI_SELL_THRESHOLD\"), (int, float, str)) else RSI_SELL_THRESHOLD\n",
        "\n",
        "            # New: Load backtesting parameters from config\n",
        "            INITIAL_CAPITAL = float(config.get(\"INITIAL_CAPITAL\", INITIAL_CAPITAL)) if isinstance(config.get(\"INITIAL_CAPITAL\"), (int, float, str)) else INITIAL_CAPITAL\n",
        "            COMMISSION_RATE = float(config.get(\"COMMISSION_RATE\", COMMISSION_RATE)) if isinstance(config.get(\"COMMISSION_RATE\"), (int, float, str)) else COMMISSION_RATE\n",
        "\n",
        "\n",
        "            config_loaded = True\n",
        "            print(f\"Configuracion cargada exitosamente desde '{config_file_path}'.\")\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: Archivo de configuracion '{config_file_path}' no encontrado. Procediendo con entrada manual.\")\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"Error: No se pudo decodificar el JSON del archivo '{config_file_path}'. Asegurese de que el archivo esta formateado correctamente. Procediendo con entrada manual.\")\n",
        "        except Exception as e:\n",
        "             print(f\"Ocurrio un error inesperado al cargar la configuracion desde '{config_file_path}': {e}. Procediendo con entrada manual.\")\n",
        "\n",
        "\n",
        "    # If configuration was not loaded from file, or if loading failed, prompt for manual input\n",
        "    if not config_loaded:\n",
        "        print(\"Por favor, ingresa los parámetros de configuración manualmente.\")\n",
        "        # Get configuration inputs from the user (existing code)\n",
        "        symbols_input = input(\"Ingrese los simbolos a monitorear separados por coma (ej. BTC-USD,ETH-USD): \")\n",
        "        # Use global SYMBOLS list here as it's referenced in fetch_data\n",
        "        SYMBOLS = [s.strip() for s in symbols_input.split(',') if s.strip()] if symbols_input else SYMBOLS\n",
        "\n",
        "        # Exit if no symbols are provided\n",
        "        if not SYMBOLS:\n",
        "            print(\"No se ingresaron simbolos. Terminando ejecucion.\")\n",
        "            processed_dfs = {} # Ensure processed_dfs is defined even if symbols are empty\n",
        "        else:\n",
        "\n",
        "            period_input = input(f\"Ingrese el periodo de descarga de datos para {SYMBOLS} (ej. 30d, 1y): \") or PERIOD\n",
        "            PERIOD = period_input\n",
        "\n",
        "            interval_input = input(f\"Ingrese el intervalo de los datos para {SYMBOLS} (ej. 5m, 1h, 1d): \") or INTERVAL\n",
        "            INTERVAL = interval_input\n",
        "\n",
        "            z_threshold_input = input(f\"Ingrese el umbral para Z-score (ej. {Z_THRESHOLD}): \") or str(Z_THRESHOLD)\n",
        "            Z_THRESHOLD = float(z_threshold_input)\n",
        "\n",
        "            if_contamination_input = input(f\"Ingrese la fraccion de anomalias esperadas para Isolation Forest (entre 0 y 1, ej. {IF_CONTAMINATION}): \") or str(IF_CONTAMINATION)\n",
        "            IF_CONTAMINATION = float(if_contamination_input)\n",
        "\n",
        "            if_features_input = input(f\"Ingrese las features para Isolation Forest separadas por coma (ej. logret,vol_20,z_price,rsi,macd,upper_band,lower_band,atr,cmf): \")\n",
        "            IF_FEATURES = [f.strip() for f in if_features_input.split(',') if f.strip()] if if_features_input else IF_FEATURES\n",
        "\n",
        "            discord_webhook_url_input = input(\"Ingrese la URL del Webhook de Discord (dejar en blanco para no usar Discord): \")\n",
        "            DISCORD_WEBHOOK_URL = discord_webhook_url_input\n",
        "\n",
        "            anomaly_threshold_input = input(f\"Ingrese el umbral de score combinado para enviar alerta (ej. {ANOMALY_THRESHOLD}): \") or str(ANOMALY_THRESHOLD)\n",
        "            ANOMALY_THRESHOLD = float(anomaly_threshold_input)\n",
        "\n",
        "            # New: Prompt for signal parameters if not loaded\n",
        "            trend_window_input = input(f\"Ingrese la ventana de la media movil para la tendencia (ej. {TREND_WINDOW}): \") or str(TREND_WINDOW)\n",
        "            TREND_WINDOW = int(trend_window_input)\n",
        "\n",
        "            rsi_buy_threshold_input = input(f\"Ingrese el umbral de RSI para señal de COMPRA (ej. {RSI_BUY_THRESHOLD}): \") or str(RSI_BUY_THRESHOLD)\n",
        "            RSI_BUY_THRESHOLD = float(rsi_buy_threshold_input)\n",
        "\n",
        "            rsi_sell_threshold_input = input(f\"Ingrese el umbral de RSI para señal de VENTA (ej. {RSI_SELL_THRESHOLD}): \") or str(RSI_SELL_THRESHOLD)\n",
        "            RSI_SELL_THRESHOLD = float(rsi_sell_threshold_input)\n",
        "\n",
        "            # New: Prompt for backtesting parameters if not loaded\n",
        "            initial_capital_input = input(f\"Ingrese el capital inicial para backtesting (ej. {INITIAL_CAPITAL}): \") or str(INITIAL_CAPITAL)\n",
        "            INITIAL_CAPITAL = float(initial_capital_input)\n",
        "\n",
        "            commission_rate_input = input(f\"Ingrese la tasa de comision por operacion (ej. {COMMISSION_RATE} para 0.1%): \") or str(COMMISSION_RATE)\n",
        "            COMMISSION_RATE = float(commission_rate_input)\n",
        "\n",
        "\n",
        "    # Continue with the rest of the execution only if symbols are available (either loaded or manually entered)\n",
        "    if SYMBOLS:\n",
        "        print(\"\\nIniciando el proceso de procesamiento de datos...\")\n",
        "        processed_dfs = {} # Dictionary to store processed dataframes for each symbol\n",
        "        for sym in SYMBOLS:\n",
        "            # Pass all configuration parameters, including new signal and backtesting ones\n",
        "            processed_dfs[sym] = run_anomaly_detection(sym, PERIOD, INTERVAL, Z_THRESHOLD, IF_CONTAMINATION, IF_FEATURES, ANOMALY_THRESHOLD, TREND_WINDOW, RSI_BUY_THRESHOLD, RSI_SELL_THRESHOLD)\n",
        "\n",
        "\n",
        "        print(\"\\nProceso de procesamiento de datos finalizado.\")\n",
        "\n",
        "        # --- Interactive Menu Options ---\n",
        "        print(\"\\n--- Opciones ---\")\n",
        "\n",
        "        # 1. Display Final Processed DataFrame\n",
        "        display_df_choice = input(\"¿Desea mostrar el dataframe final procesado para el primer simbolo? (s/n): \").lower()\n",
        "        if display_df_choice == 's':\n",
        "            if SYMBOLS and SYMBOLS[0] in processed_dfs and processed_dfs[SYMBOLS[0]] is not None and not processed_dfs[SYMBOLS[0]].empty:\n",
        "                df_final = processed_dfs[SYMBOLS[0]]\n",
        "                print(f\"\\nFinal processed DataFrame for {SYMBOLS[0]}:\")\n",
        "                display(df_final.tail()) # Use display for DataFrames in Colab\n",
        "            elif SYMBOLS:\n",
        "                print(f\"\\nNo se pudo obtener o procesar datos para el primer simbolo: {SYMBOLS[0]}. No se puede mostrar el dataframe.\")\n",
        "            else:\n",
        "                 print(\"\\nNo se especificaron simbolos para procesar.\")\n",
        "\n",
        "\n",
        "        # 2. Visualize Data and Anomalies (for the first symbol processed)\n",
        "        visualize_choice = input(f\"¿Desea ver los gráficos de datos, características, anomalías y señales para {SYMBOLS[0]}? (s/n): \").lower()\n",
        "        if visualize_choice == 's':\n",
        "            if SYMBOLS and SYMBOLS[0] in processed_dfs and processed_dfs[SYMBOLS[0]] is not None and not processed_dfs[SYMBOLS[0]].empty:\n",
        "                df_to_visualize = processed_dfs[SYMBOLS[0]]\n",
        "                visualize_data_features(df_to_visualize, SYMBOLS[0], SYMBOLS)\n",
        "                visualize_anomalies(df_to_visualize, SYMBOLS[0], ANOMALY_THRESHOLD)\n",
        "            elif SYMBOLS:\n",
        "                print(f\"\\nNo se pudo obtener o procesar datos para el primer simbolo: {SYMBOLS[0]}. No se pueden generar gráficos.\")\n",
        "            else:\n",
        "                 print(\"\\nNo se especificaron simbolos para procesar.\")\n",
        "\n",
        "        # 3. Run Backtesting (for the first symbol processed)\n",
        "        backtest_choice = input(f\"¿Desea ejecutar el backtesting para el primer simbolo ({SYMBOLS[0]})? (s/n): \").lower() if SYMBOLS else 'n'\n",
        "        if backtest_choice == 's':\n",
        "             if SYMBOLS and SYMBOLS[0] in processed_dfs and processed_dfs[SYMBOLS[0]] is not None and not processed_dfs[SYMBOLS[0]].empty:\n",
        "                  df_to_backtest = processed_dfs[SYMBOLS[0]]\n",
        "                  print(f\"\\nEjecutando backtesting para {SYMBOLS[0]} con Capital Inicial: {INITIAL_CAPITAL}, Comisión: {COMMISSION_RATE}...\")\n",
        "                  backtest_results = backtest_strategy(df_to_backtest, initial_capital=INITIAL_CAPITAL, commission_rate=COMMISSION_RATE)\n",
        "\n",
        "                  if backtest_results:\n",
        "                       print(\"\\n--- Resultados del Backtesting ---\")\n",
        "                       print(f\"Símbolo: {SYMBOLS[0]}\")\n",
        "                       print(f\"Capital Inicial: {backtest_results['initial_capital']:.2f}\")\n",
        "                       print(f\"Capital Final: {backtest_results['final_capital']:.2f}\")\n",
        "                       print(f\"P/L Total: {backtest_results['total_profit_loss']:.2f}\")\n",
        "                       print(f\"Retorno Porcentual: {backtest_results['return_percentage']:.2f}%\")\n",
        "                       print(f\"Número de Operaciones: {backtest_results['num_trades']}\")\n",
        "                       print(f\"Tasa de Éxito: {backtest_results['win_rate']:.2f}\")\n",
        "                       print(f\"Ganancia Total (Operaciones Ganadoras): {backtest_results['total_winning_profit']:.2f}\")\n",
        "                       print(f\"Pérdida Total (Operaciones Perdedoras): {backtest_results['total_losing_loss']:.2f}\")\n",
        "                       print(f\"Ganancia Promedio por Operación Ganadora: {backtest_results['avg_profit_per_winning_trade']:.2f}\")\n",
        "                       print(f\"Pérdida Promedio por Operación Perdedora: {backtest_results['avg_loss_per_losing_trade']:.2f}\")\n",
        "                       print(f\"Factor de Ganancia: {backtest_results['profit_factor']:.2f}\" if pd.notna(backtest_results['profit_factor']) else \"Factor de Ganancia: N/A\")\n",
        "                       print(f\"Máximo Drawdown: {backtest_results['max_drawdown']:.2f}\")\n",
        "\n",
        "                       # Optionally display individual trades\n",
        "                       display_trades_choice = input(\"¿Desea mostrar los detalles de cada operación? (s/n): \").lower()\n",
        "                       if display_trades_choice == 's' and 'trades' in backtest_results and backtest_results['trades']:\n",
        "                            print(\"\\n--- Detalles de las Operaciones ---\")\n",
        "                            trades_df = pd.DataFrame(backtest_results['trades'])\n",
        "                            display(trades_df)\n",
        "                       elif display_trades_choice == 's':\n",
        "                            print(\"No hay operaciones para mostrar.\")\n",
        "\n",
        "                  else:\n",
        "                       print(\"\\nNo se pudieron calcular los resultados del backtesting.\")\n",
        "\n",
        "             elif SYMBOLS:\n",
        "                 print(f\"\\nNo se pudo obtener o procesar datos para el primer simbolo: {SYMBOLS[0]}. No se puede ejecutar el backtesting.\")\n",
        "             else:\n",
        "                 print(\"\\nNo se especificaron simbolos para procesar.\")\n",
        "\n",
        "\n",
        "        # 4. Send Discord Alert (based on the last point processed for EACH symbol)\n",
        "        # Shifted Discord alert to be option 4 after backtesting\n",
        "        print(\"\\n--- Verificación de Alertas (último punto procesado por cada simbolo) ---\")\n",
        "        for sym in SYMBOLS:\n",
        "            if sym in processed_dfs and processed_dfs[sym] is not None and not processed_dfs[sym].empty:\n",
        "                 df_sym = processed_dfs[sym]\n",
        "                 latest_sym = df_sym.iloc[-1]\n",
        "\n",
        "                 score_sym = latest_sym.get(\"final_score\", pd.Series([np.nan])).item()\n",
        "                 rule_combo_status_sym = bool(latest_sym.get(\"rule_combo\", False))\n",
        "                 buy_signal_latest_sym = bool(latest_sym.get('buy_signal', False))\n",
        "                 sell_signal_latest_sym = bool(latest_sym.get('sell_signal', False))\n",
        "\n",
        "                 # Construct message if alert condition is met for the latest point of THIS symbol\n",
        "                 # Updated alert message to include more details about the signal conditions if a signal is generated\n",
        "                 if (pd.notna(score_sym) and score_sym > ANOMALY_THRESHOLD) or rule_combo_status_sym or buy_signal_latest_sym or sell_signal_latest_sym:\n",
        "                     msg_lines = [f\"🚨 ALERTA {sym} (Último Punto Procesado) 🚨\"]\n",
        "                     latest_time_formatted = \"N/A\"\n",
        "                     try:\n",
        "                         latest_time_str = str(latest_sym.name)\n",
        "                         try:\n",
        "                             latest_time_naive = datetime.fromisoformat(latest_time_str.replace('Z', '+00:00'))\n",
        "                         except ValueError:\n",
        "                              try:\n",
        "                                   latest_time_naive = datetime.strptime(latest_time_str.split('.')[0].split('+')[0], '%Y-%m-%d %H:%M:%S')\n",
        "                              except ValueError:\n",
        "                                   latest_time_naive = None\n",
        "\n",
        "\n",
        "                         if latest_time_naive:\n",
        "                              latest_time_formatted = latest_time_naive.strftime('%Y-%m-%d %H:%M:%S') + \" UTC\"\n",
        "                         else:\n",
        "                              latest_time_formatted = str(latest_sym.name)\n",
        "\n",
        "                     except Exception as e:\n",
        "                         print(f\"Error formatting timestamp for {sym}: {e}\")\n",
        "                         latest_time_formatted = str(latest_sym.name)\n",
        "\n",
        "\n",
        "                     msg_lines.append(f\"Time: {latest_time_formatted}\")\n",
        "                     msg_lines.append(f\"Score Combinado: {score_sym:.3f}\" if pd.notna(score_sym) else \"Score Combinado: N/A\")\n",
        "                     close_price_latest_sym = latest_sym.get(\"Close\", np.nan)\n",
        "                     z_price_latest_sym = latest_sym.get(\"z_price\", np.nan)\n",
        "                     vol_z_latest_sym = latest_sym.get(\"vol_z\", np.nan)\n",
        "\n",
        "                     msg_lines.append(f\"Precio: {close_price_latest_sym:.2f}\" if pd.notna(close_price_latest_sym) else \"Precio: N/A\")\n",
        "                     msg_lines.append(f\"z_precio: {z_price_latest_sym:.2f}\" if pd.notna(z_price_latest_sym) else \"z_precio: N/A\")\n",
        "                     msg_lines.append(f\"vol_z: {vol_z_latest_sym:.2f}\" if pd.notna(vol_z_latest_sym) else \"vol_z: N/A\")\n",
        "\n",
        "                     msg_lines.append(f\"Regla combinada activa: {rule_combo_status_sym}\")\n",
        "\n",
        "                     # Add signal information to the message if they exist and are True\n",
        "                     if 'buy_signal' in latest_sym and latest_sym['buy_signal'].item():\n",
        "                         msg_lines.append(\"📊 SEÑAL: COMPRA\")\n",
        "                         # Add details if available\n",
        "                         if 'is_uptrend' in latest_sym: msg_lines.append(f\"  - Tendencia: {'Alcista' if latest_sym['is_uptrend'].item() else 'Bajista/Lateral'}\")\n",
        "                         if 'rsi' in latest_sym: msg_lines.append(f\"  - RSI: {latest_sym['rsi'].item():.2f} (Umbral Compra: {RSI_BUY_THRESHOLD})\")\n",
        "                         if 'final_score' in latest_sym: msg_lines.append(f\"  - Score Anomalia: {latest_sym['final_score'].item():.3f}\")\n",
        "\n",
        "\n",
        "                     if 'sell_signal' in latest_sym and latest_sym['sell_signal'].item():\n",
        "                         msg_lines.append(\"📉 SEÑAL: VENTA\")\n",
        "                         # Add details if available\n",
        "                         if 'is_downtrend' in latest_sym: msg_lines.append(f\"  - Tendencia: {'Bajista' if latest_sym['is_downtrend'].item() else 'Alcista/Lateral'}\")\n",
        "                         if 'rsi' in latest_sym: msg_lines.append(f\"  - RSI: {latest_sym['rsi'].item():.2f} (Umbral Venta: {RSI_SELL_THRESHOLD})\")\n",
        "                         if 'final_score' in latest_sym: msg_lines.append(f\"  - Score Anomalia: {latest_sym['final_score'].item():.3f}\")\n",
        "\n",
        "\n",
        "                     alert_msg = \"\\n\".join(msg_lines)\n",
        "                     print(\"\\n\" + alert_msg)\n",
        "\n",
        "                     send_discord_message(alert_msg, DISCORD_WEBHOOK_URL)\n",
        "                 else:\n",
        "                     print(f\"\\n✅ {sym}: OK, no se detecto alerta en el último punto procesado.\")\n",
        "            elif sym in SYMBOLS:\n",
        "                 print(f\"\\nNo se pudo procesar datos para {sym}. No se verificó alerta.\")\n",
        "\n",
        "\n",
        "        # 5. Download Processed DataFrame as CSV (for the first symbol processed)\n",
        "        # Shifted Download to be option 5 after backtesting and alerts\n",
        "        download_choice = input(f\"\\n¿Desea descargar el dataframe procesado para el primer simbolo ({SYMBOLS[0]}) como CSV? (s/n): \").lower() if SYMBOLS else 'n'\n",
        "        if download_choice == 's':\n",
        "             if SYMBOLS and SYMBOLS[0] in processed_dfs and processed_dfs[SYMBOLS[0]] is not None and not processed_dfs[SYMBOLS[0]].empty:\n",
        "                 df_to_download = processed_dfs[SYMBOLS[0]]\n",
        "                 csv_filename = f\"{SYMBOLS[0]}_anomalies_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "                 try:\n",
        "                     df_to_csv_ready = df_to_download.copy()\n",
        "                     if df_to_csv_ready.index.name:\n",
        "                         df_to_csv_ready.index.name = 'Date'\n",
        "                         df_to_csv_ready = df_to_csv_ready.reset_index()\n",
        "                     else:\n",
        "                         df_to_csv_ready = df_to_csv_ready.reset_index()\n",
        "                         if 'index' in df_to_csv_ready.columns:\n",
        "                              df_to_csv_ready = df_to_csv_ready.rename(columns={'index': 'Date'})\n",
        "\n",
        "\n",
        "                     df_to_csv_ready.to_csv(csv_filename, index=False)\n",
        "                     print(f\"\\nDataFrame guardado como '{csv_filename}'. Iniciando descarga...\")\n",
        "                     try:\n",
        "                         files.download(csv_filename)\n",
        "                         print(\"Descarga iniciada.\")\n",
        "                     except Exception as e:\n",
        "                          print(f\"Error durante la descarga: {e}. Puedes intentar descargar el archivo manualmente desde el explorador de archivos de Colab.\")\n",
        "                 except Exception as e:\n",
        "                     print(f\"Error al preparar o guardar el CSV: {e}\")\n",
        "\n",
        "\n",
        "             elif SYMBOLS:\n",
        "                 print(f\"\\nNo se pudo obtener o procesar datos para el primer simbolo: {SYMBOLS[0]}. No se puede descargar el CSV.\")\n",
        "             else:\n",
        "                 print(\"\\nNo se especificaron simbolos para procesar.\")\n",
        "\n",
        "\n",
        "    print(\"\\n--- Fin de la Ejecución ---\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Bot de Detección de Anomalías y Señales ---\n",
            "¿Desea cargar la configuracion desde un archivo (ej. config.json)? (s/n): n\n",
            "Por favor, ingresa los parámetros de configuración manualmente.\n",
            "Ingrese los simbolos a monitorear separados por coma (ej. BTC-USD,ETH-USD): BTC-USD\n",
            "Ingrese el periodo de descarga de datos para ['BTC-USD'] (ej. 30d, 1y): 1Y\n",
            "Ingrese el intervalo de los datos para ['BTC-USD'] (ej. 5m, 1h, 1d): 1D\n",
            "Ingrese el umbral para Z-score (ej. 3.0): 3.0\n",
            "Ingrese la fraccion de anomalias esperadas para Isolation Forest (entre 0 y 1, ej. 0.01): 0.01\n",
            "Ingrese las features para Isolation Forest separadas por coma (ej. logret,vol_20,z_price,rsi,macd,upper_band,lower_band,atr,cmf): logret,vol_20,z_price,rsi,macd\n",
            "Ingrese la URL del Webhook de Discord (dejar en blanco para no usar Discord): \n",
            "Ingrese el umbral de score combinado para enviar alerta (ej. 0.6): 0.6\n",
            "Ingrese la ventana de la media movil para la tendencia (ej. 50): 50\n",
            "Ingrese el umbral de RSI para señal de COMPRA (ej. 30): 30\n",
            "Ingrese el umbral de RSI para señal de VENTA (ej. 70): 70\n",
            "Ingrese el capital inicial para backtesting (ej. 10000): 10000\n",
            "Ingrese la tasa de comision por operacion (ej. 0.001 para 0.1%): 0.001\n",
            "\n",
            "Iniciando el proceso de procesamiento de datos...\n",
            "\n",
            "--- Procesando simbolo: BTC-USD ---\n",
            "Descargando datos para: BTC-USD (Periodo: 1Y, Intervalo: 1D)\n",
            "Diagnóstico Fetch: Detectado MultiIndex para BTC-USD. Aplanando columnas.\n",
            "Diagnóstico Fetch: Columnas aplanadas y seleccionadas para BTC-USD: ['Open', 'High', 'Low', 'Close', 'Volume']\n",
            "\n",
            "Resumen para el ultimo punto de BTC-USD:\n",
            "Score Combinado: 0.214\n",
            "Regla combinada activa: False\n",
            "Señal de compra: False\n",
            "Señal de venta: False\n",
            "\n",
            "No hay ALERTA para BTC-USD en el último punto procesado.\n",
            "\n",
            "Proceso de procesamiento de datos finalizado.\n",
            "\n",
            "--- Opciones ---\n",
            "¿Desea mostrar el dataframe final procesado para el primer simbolo? (s/n): s\n",
            "\n",
            "Final processed DataFrame for BTC-USD:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                     Open           High            Low          Close  \\\n",
              "Date                                                                     \n",
              "2025-09-10  111531.250000  114275.250000  110940.078125  113955.359375   \n",
              "2025-09-11  113961.429688  115522.546875  113453.835938  115507.539062   \n",
              "2025-09-12  115507.789062  116769.382812  114794.484375  116101.578125   \n",
              "2025-09-13  116093.562500  116334.632812  115248.273438  115950.507812   \n",
              "2025-09-15  115377.843750  115554.171875  114914.414062  115443.796875   \n",
              "\n",
              "                 Volume    logret    vol_10    vol_20   z_price     vol_z  \\\n",
              "Date                                                                        \n",
              "2025-09-10  56377473784  0.021508  0.156709  0.277772  1.124917 -0.144489   \n",
              "2025-09-11  45685065332  0.013529  0.161203  0.244095  2.003160 -0.689093   \n",
              "2025-09-12  54785725894  0.005130  0.146409  0.240385  2.190588 -0.133692   \n",
              "2025-09-13  34549454947 -0.001302  0.149043  0.231951  1.893119 -1.228189   \n",
              "2025-09-15  33916383232 -0.004380  0.139540  0.202716  1.478238 -1.183846   \n",
              "\n",
              "            ...  rule_price_z  rule_vol_spike  rule_combo  if_score  \\\n",
              "Date        ...                                                       \n",
              "2025-09-10  ...         False           False       False -0.186670   \n",
              "2025-09-11  ...         False           False       False -0.172707   \n",
              "2025-09-12  ...         False           False       False -0.171151   \n",
              "2025-09-13  ...         False           False       False -0.195119   \n",
              "2025-09-15  ...         False           False       False -0.188270   \n",
              "\n",
              "            if_score_norm    z_norm  vol_norm  final_score  buy_signal  \\\n",
              "Date                                                                     \n",
              "2025-09-10       0.188488  0.307850       0.0     0.186599       False   \n",
              "2025-09-11       0.232693  0.552318       0.0     0.282042       False   \n",
              "2025-09-12       0.237620  0.604491       0.0     0.300157       False   \n",
              "2025-09-13       0.161742  0.521687       0.0     0.237377       False   \n",
              "2025-09-15       0.183425  0.406201       0.0     0.213572       False   \n",
              "\n",
              "            sell_signal  \n",
              "Date                     \n",
              "2025-09-10        False  \n",
              "2025-09-11        False  \n",
              "2025-09-12        False  \n",
              "2025-09-13        False  \n",
              "2025-09-15        False  \n",
              "\n",
              "[5 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7610f5bc-f230-4534-b6aa-17b4238f89a3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>logret</th>\n",
              "      <th>vol_10</th>\n",
              "      <th>vol_20</th>\n",
              "      <th>z_price</th>\n",
              "      <th>vol_z</th>\n",
              "      <th>...</th>\n",
              "      <th>rule_price_z</th>\n",
              "      <th>rule_vol_spike</th>\n",
              "      <th>rule_combo</th>\n",
              "      <th>if_score</th>\n",
              "      <th>if_score_norm</th>\n",
              "      <th>z_norm</th>\n",
              "      <th>vol_norm</th>\n",
              "      <th>final_score</th>\n",
              "      <th>buy_signal</th>\n",
              "      <th>sell_signal</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2025-09-10</th>\n",
              "      <td>111531.250000</td>\n",
              "      <td>114275.250000</td>\n",
              "      <td>110940.078125</td>\n",
              "      <td>113955.359375</td>\n",
              "      <td>56377473784</td>\n",
              "      <td>0.021508</td>\n",
              "      <td>0.156709</td>\n",
              "      <td>0.277772</td>\n",
              "      <td>1.124917</td>\n",
              "      <td>-0.144489</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.186670</td>\n",
              "      <td>0.188488</td>\n",
              "      <td>0.307850</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.186599</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-11</th>\n",
              "      <td>113961.429688</td>\n",
              "      <td>115522.546875</td>\n",
              "      <td>113453.835938</td>\n",
              "      <td>115507.539062</td>\n",
              "      <td>45685065332</td>\n",
              "      <td>0.013529</td>\n",
              "      <td>0.161203</td>\n",
              "      <td>0.244095</td>\n",
              "      <td>2.003160</td>\n",
              "      <td>-0.689093</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.172707</td>\n",
              "      <td>0.232693</td>\n",
              "      <td>0.552318</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.282042</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-12</th>\n",
              "      <td>115507.789062</td>\n",
              "      <td>116769.382812</td>\n",
              "      <td>114794.484375</td>\n",
              "      <td>116101.578125</td>\n",
              "      <td>54785725894</td>\n",
              "      <td>0.005130</td>\n",
              "      <td>0.146409</td>\n",
              "      <td>0.240385</td>\n",
              "      <td>2.190588</td>\n",
              "      <td>-0.133692</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.171151</td>\n",
              "      <td>0.237620</td>\n",
              "      <td>0.604491</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.300157</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-13</th>\n",
              "      <td>116093.562500</td>\n",
              "      <td>116334.632812</td>\n",
              "      <td>115248.273438</td>\n",
              "      <td>115950.507812</td>\n",
              "      <td>34549454947</td>\n",
              "      <td>-0.001302</td>\n",
              "      <td>0.149043</td>\n",
              "      <td>0.231951</td>\n",
              "      <td>1.893119</td>\n",
              "      <td>-1.228189</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.195119</td>\n",
              "      <td>0.161742</td>\n",
              "      <td>0.521687</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.237377</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-15</th>\n",
              "      <td>115377.843750</td>\n",
              "      <td>115554.171875</td>\n",
              "      <td>114914.414062</td>\n",
              "      <td>115443.796875</td>\n",
              "      <td>33916383232</td>\n",
              "      <td>-0.004380</td>\n",
              "      <td>0.139540</td>\n",
              "      <td>0.202716</td>\n",
              "      <td>1.478238</td>\n",
              "      <td>-1.183846</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>-0.188270</td>\n",
              "      <td>0.183425</td>\n",
              "      <td>0.406201</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.213572</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7610f5bc-f230-4534-b6aa-17b4238f89a3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7610f5bc-f230-4534-b6aa-17b4238f89a3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7610f5bc-f230-4534-b6aa-17b4238f89a3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1967a160-bff8-400a-a343-0985e2712782\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1967a160-bff8-400a-a343-0985e2712782')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1967a160-bff8-400a-a343-0985e2712782 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}